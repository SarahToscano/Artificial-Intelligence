{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prova 2 de Intelig√™ncia Artificial\n",
    "### Aluna: Sarah Andrade Toscano de Carvalho  \n",
    "### Matr√≠cula:20170022895    --    Prof¬™: Tha√≠s Gaudencio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quest√£o 1\n",
    "\n",
    "Acessar a base de dados HCV (https://archive.ics.uci.edu/ml/datasets/HCV+data#) e desenvolver dois algoritmos supervisionados, podendo ser Redes Neurais Artificiais, √Årvore de Decis√£o ou outros de sua escolha, para classifica√ß√£o entre Doador ou N√£o Doador, que s√£o positivos para Hepatite C, Fibrose ou Cirrose. Ambos modelos devem ser analisados pelas m√©tricas: Acur√°cia, Especificidade, Sensibilidade e Matriz de Confus√£o e os resultados devem ser discutidos. Na base consta inst√¢ncias rotuladas como Poss√≠veis Doadores (0s=suspect Blood Donor), que devem ser classificadas separadamente ap√≥s a constru√ß√£o dos modelos, compare os resultados obtidos em cada m√©todo utilizado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importa√ß√£o das bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importa√ß√£o da base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('./database/data-Q1.csv', delimiter=',', index_col=0)\n",
    "dataset['Sex'] = dataset['Sex'].replace({'m': 0, 'f': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ALB</th>\n",
       "      <th>ALP</th>\n",
       "      <th>ALT</th>\n",
       "      <th>AST</th>\n",
       "      <th>BIL</th>\n",
       "      <th>CHE</th>\n",
       "      <th>CHOL</th>\n",
       "      <th>CREA</th>\n",
       "      <th>GGT</th>\n",
       "      <th>PROT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0=Blood Donor</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>38.5</td>\n",
       "      <td>52.5</td>\n",
       "      <td>7.7</td>\n",
       "      <td>22.1</td>\n",
       "      <td>7.5</td>\n",
       "      <td>6.93</td>\n",
       "      <td>3.23</td>\n",
       "      <td>106.0</td>\n",
       "      <td>12.1</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0=Blood Donor</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>38.5</td>\n",
       "      <td>70.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>24.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>11.17</td>\n",
       "      <td>4.80</td>\n",
       "      <td>74.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>76.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0=Blood Donor</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>46.9</td>\n",
       "      <td>74.7</td>\n",
       "      <td>36.2</td>\n",
       "      <td>52.6</td>\n",
       "      <td>6.1</td>\n",
       "      <td>8.84</td>\n",
       "      <td>5.20</td>\n",
       "      <td>86.0</td>\n",
       "      <td>33.2</td>\n",
       "      <td>79.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0=Blood Donor</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>43.2</td>\n",
       "      <td>52.0</td>\n",
       "      <td>30.6</td>\n",
       "      <td>22.6</td>\n",
       "      <td>18.9</td>\n",
       "      <td>7.33</td>\n",
       "      <td>4.74</td>\n",
       "      <td>80.0</td>\n",
       "      <td>33.8</td>\n",
       "      <td>75.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0=Blood Donor</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>39.2</td>\n",
       "      <td>74.1</td>\n",
       "      <td>32.6</td>\n",
       "      <td>24.8</td>\n",
       "      <td>9.6</td>\n",
       "      <td>9.15</td>\n",
       "      <td>4.32</td>\n",
       "      <td>76.0</td>\n",
       "      <td>29.9</td>\n",
       "      <td>68.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Category  Age  Sex   ALB   ALP   ALT   AST   BIL    CHE  CHOL   CREA  \\\n",
       "1  0=Blood Donor   32    0  38.5  52.5   7.7  22.1   7.5   6.93  3.23  106.0   \n",
       "2  0=Blood Donor   32    0  38.5  70.3  18.0  24.7   3.9  11.17  4.80   74.0   \n",
       "3  0=Blood Donor   32    0  46.9  74.7  36.2  52.6   6.1   8.84  5.20   86.0   \n",
       "4  0=Blood Donor   32    0  43.2  52.0  30.6  22.6  18.9   7.33  4.74   80.0   \n",
       "5  0=Blood Donor   32    0  39.2  74.1  32.6  24.8   9.6   9.15  4.32   76.0   \n",
       "\n",
       "    GGT  PROT  \n",
       "1  12.1  69.0  \n",
       "2  15.6  76.5  \n",
       "3  33.2  79.3  \n",
       "4  33.8  75.7  \n",
       "5  29.9  68.7  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0=Blood Donor             533\n",
       "0s=suspect Blood Donor      7\n",
       "1=Hepatitis                24\n",
       "2=Fibrosis                 21\n",
       "3=Cirrhosis                30\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"Category\"].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pr√©-processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verifica√ß√£o de dados nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category     0\n",
       "Age          0\n",
       "Sex          0\n",
       "ALB          1\n",
       "ALP         18\n",
       "ALT          1\n",
       "AST          0\n",
       "BIL          0\n",
       "CHE          0\n",
       "CHOL        10\n",
       "CREA         0\n",
       "GGT          0\n",
       "PROT         1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ALB</th>\n",
       "      <th>ALP</th>\n",
       "      <th>ALT</th>\n",
       "      <th>AST</th>\n",
       "      <th>BIL</th>\n",
       "      <th>CHE</th>\n",
       "      <th>CHOL</th>\n",
       "      <th>CREA</th>\n",
       "      <th>GGT</th>\n",
       "      <th>PROT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>1=Hepatitis</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.55</td>\n",
       "      <td>3.9</td>\n",
       "      <td>62.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>1=Hepatitis</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8.79</td>\n",
       "      <td>3.6</td>\n",
       "      <td>79.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>1=Hepatitis</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.16</td>\n",
       "      <td>6.1</td>\n",
       "      <td>86.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>2=Fibrosis</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>118.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.28</td>\n",
       "      <td>3.5</td>\n",
       "      <td>72.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>2=Fibrosis</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>114.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.43</td>\n",
       "      <td>5.2</td>\n",
       "      <td>72.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>2=Fibrosis</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>258.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8.74</td>\n",
       "      <td>4.7</td>\n",
       "      <td>77.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>2=Fibrosis</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.77</td>\n",
       "      <td>4.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>2=Fibrosis</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.92</td>\n",
       "      <td>4.7</td>\n",
       "      <td>79.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>2=Fibrosis</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.21</td>\n",
       "      <td>3.1</td>\n",
       "      <td>89.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>2=Fibrosis</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>37.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>164.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.99</td>\n",
       "      <td>4.2</td>\n",
       "      <td>67.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>2=Fibrosis</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.75</td>\n",
       "      <td>5.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>2=Fibrosis</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>114.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>3=Cirrhosis</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.37</td>\n",
       "      <td>3.2</td>\n",
       "      <td>61.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>3=Cirrhosis</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>1.48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>114.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>3=Cirrhosis</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>159.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.29</td>\n",
       "      <td>5.5</td>\n",
       "      <td>58.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>3=Cirrhosis</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>3=Cirrhosis</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.56</td>\n",
       "      <td>4.2</td>\n",
       "      <td>52.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>3=Cirrhosis</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.07</td>\n",
       "      <td>5.3</td>\n",
       "      <td>67.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Category  Age  Sex   ALB  ALP    ALT    AST    BIL    CHE  CHOL  \\\n",
       "542  1=Hepatitis   19    0  41.0  NaN   87.0   67.0   12.0   7.55   3.9   \n",
       "546  1=Hepatitis   29    0  49.0  NaN   53.0   39.0   15.0   8.79   3.6   \n",
       "547  1=Hepatitis   30    0  45.0  NaN   66.0   45.0   14.0  12.16   6.1   \n",
       "569   2=Fibrosis   49    0  39.0  NaN  118.0   62.0   10.0   7.28   3.5   \n",
       "570   2=Fibrosis   49    0  46.0  NaN  114.0   75.0   16.0  10.43   5.2   \n",
       "571   2=Fibrosis   50    0  42.0  NaN  258.0  106.0   15.0   8.74   4.7   \n",
       "572   2=Fibrosis   53    0  46.0  NaN   34.0   43.0   14.0   8.77   4.0   \n",
       "577   2=Fibrosis   71    0  37.0  NaN  130.0   90.0   15.0   9.92   4.7   \n",
       "582   2=Fibrosis   49    1  39.0  NaN   46.0   39.0    9.0  10.21   3.1   \n",
       "583   2=Fibrosis   51    1  37.0  NaN  164.0   70.0    9.0   3.99   4.2   \n",
       "584   2=Fibrosis   56    1  39.0  NaN   42.0   34.0   10.0   7.75   5.0   \n",
       "585   2=Fibrosis   75    1  36.0  NaN  114.0  125.0   14.0   6.65   NaN   \n",
       "586  3=Cirrhosis   38    0  44.0  NaN   94.0   60.0   12.0   4.37   3.2   \n",
       "591  3=Cirrhosis   46    0  20.0  NaN   62.0  113.0  254.0   1.48   NaN   \n",
       "593  3=Cirrhosis   47    0  42.0  NaN  159.0  102.0   11.0   6.29   5.5   \n",
       "604  3=Cirrhosis   65    0   NaN  NaN   40.0   54.0   13.0   7.50   NaN   \n",
       "614  3=Cirrhosis   46    1  33.0  NaN   39.0   62.0   20.0   3.56   4.2   \n",
       "615  3=Cirrhosis   59    1  36.0  NaN  100.0   80.0   12.0   9.07   5.3   \n",
       "\n",
       "      CREA    GGT  PROT  \n",
       "542   62.0   65.0  75.0  \n",
       "546   79.0   37.0  90.0  \n",
       "547   86.0   43.0  77.0  \n",
       "569   72.0   74.0  81.0  \n",
       "570   72.0   59.0  82.0  \n",
       "571   77.0   80.0  84.0  \n",
       "572  112.0  203.0  76.0  \n",
       "577   79.0   77.0  76.0  \n",
       "582   89.0   53.0  79.0  \n",
       "583   67.0   43.0  72.0  \n",
       "584   80.0   84.0  78.0  \n",
       "585   57.0  177.0  72.0  \n",
       "586   61.0   99.0  77.0  \n",
       "591  114.0  138.0   NaN  \n",
       "593   58.0  201.0  79.0  \n",
       "604   70.0  107.0  79.0  \n",
       "614   52.0   50.0  71.0  \n",
       "615   67.0   34.0  68.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.query(\"ALP.isnull()\", engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([542, 546, 547, 569, 570, 571, 572, 577, 582, 583, 584, 585, 586,\n",
      "            591, 593, 604, 614, 615],\n",
      "           dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "a= dataset.query(\"ALP.isnull()\", engine='python')[\"Category\"]\n",
    "print(a.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= dataset.query(\"ALP.isnull()\", engine='python')[\"Category\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ALB</th>\n",
       "      <th>ALP</th>\n",
       "      <th>ALT</th>\n",
       "      <th>AST</th>\n",
       "      <th>BIL</th>\n",
       "      <th>CHE</th>\n",
       "      <th>CHOL</th>\n",
       "      <th>CREA</th>\n",
       "      <th>GGT</th>\n",
       "      <th>PROT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0=Blood Donor</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>48.6</td>\n",
       "      <td>45.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>40.5</td>\n",
       "      <td>5.3</td>\n",
       "      <td>7.09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.0</td>\n",
       "      <td>25.1</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>0=Blood Donor</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>47.4</td>\n",
       "      <td>52.5</td>\n",
       "      <td>19.1</td>\n",
       "      <td>17.1</td>\n",
       "      <td>4.6</td>\n",
       "      <td>10.19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>72.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>0=Blood Donor</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>42.4</td>\n",
       "      <td>137.2</td>\n",
       "      <td>14.2</td>\n",
       "      <td>13.1</td>\n",
       "      <td>3.4</td>\n",
       "      <td>8.23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.0</td>\n",
       "      <td>25.7</td>\n",
       "      <td>74.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>0=Blood Donor</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>42.9</td>\n",
       "      <td>55.1</td>\n",
       "      <td>15.2</td>\n",
       "      <td>29.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>8.37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>71.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>0=Blood Donor</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>45.6</td>\n",
       "      <td>107.2</td>\n",
       "      <td>24.4</td>\n",
       "      <td>39.0</td>\n",
       "      <td>13.8</td>\n",
       "      <td>9.77</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>75.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>0=Blood Donor</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>46.8</td>\n",
       "      <td>93.3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>4.3</td>\n",
       "      <td>12.41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.0</td>\n",
       "      <td>23.9</td>\n",
       "      <td>72.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0=Blood Donor</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>48.4</td>\n",
       "      <td>94.4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>39.6</td>\n",
       "      <td>2.3</td>\n",
       "      <td>8.84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>76.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>2=Fibrosis</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>114.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>3=Cirrhosis</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>1.48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>114.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>3=Cirrhosis</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Category  Age  Sex   ALB    ALP    ALT    AST    BIL    CHE  CHOL  \\\n",
       "122  0=Blood Donor   43    0  48.6   45.0   10.5   40.5    5.3   7.09   NaN   \n",
       "320  0=Blood Donor   32    1  47.4   52.5   19.1   17.1    4.6  10.19   NaN   \n",
       "330  0=Blood Donor   33    1  42.4  137.2   14.2   13.1    3.4   8.23   NaN   \n",
       "414  0=Blood Donor   46    1  42.9   55.1   15.2   29.8    3.6   8.37   NaN   \n",
       "425  0=Blood Donor   48    1  45.6  107.2   24.4   39.0   13.8   9.77   NaN   \n",
       "434  0=Blood Donor   48    1  46.8   93.3   10.0   23.2    4.3  12.41   NaN   \n",
       "499  0=Blood Donor   57    1  48.4   94.4    2.5   39.6    2.3   8.84   NaN   \n",
       "585     2=Fibrosis   75    1  36.0    NaN  114.0  125.0   14.0   6.65   NaN   \n",
       "591    3=Cirrhosis   46    0  20.0    NaN   62.0  113.0  254.0   1.48   NaN   \n",
       "604    3=Cirrhosis   65    0   NaN    NaN   40.0   54.0   13.0   7.50   NaN   \n",
       "\n",
       "      CREA    GGT  PROT  \n",
       "122   63.0   25.1  70.0  \n",
       "320   63.0   23.0  72.2  \n",
       "330   48.0   25.7  74.4  \n",
       "414   61.0   29.0  71.9  \n",
       "425   88.0   38.0  75.1  \n",
       "434   52.0   23.9  72.4  \n",
       "499   82.0    6.4  76.8  \n",
       "585   57.0  177.0  72.0  \n",
       "591  114.0  138.0   NaN  \n",
       "604   70.0  107.0  79.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.query(\"CHOL.isnull()\", engine='python')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Divis√£o do dataset em dados de entrada (x) e de sa√≠da (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset.iloc[:, 1:].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset.iloc[:, 0:1].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(615, 12)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dimens√£o dos dados\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üìà An√°lise Gr√°fica antes do pr√©-processamento dos dados ausentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'ALP')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset[\"ALP\"].plot.box(grid = True, figsize=(8,6))\n",
    "plt.title('ALP', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'CHOL')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset[\"CHOL\"].plot.box(grid = True, figsize=(8,6))\n",
    "plt.title('CHOL', fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tratando dados ausentes, substitui√ß√£o pela mediana\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "imputer.fit(x[:, 2:])\n",
    "x[:, 2:] = imputer.transform(x[:, 2:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codifica√ß√£o da Vari√°vel Dependente\n",
    "‚Üí Inicialmente todos os 4 r√≥tulos do atributo _category_ ser√£o codificados de string para n√∫meros inteiros de 0-4, onde:\n",
    "- 0: Blood Donor\n",
    "- 1: Suspect Blood Donor\n",
    "- 2: Hepatitis\n",
    "- 3: Fibrosis\n",
    "- 4: Cirrhosis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚Üí E em seguida, √© realizada uma nova an√°lise desses novos valores com o intuito de identificar quais deles s√£o referentes ao casos: \n",
    "- Suspect Blood Donor (-1)\n",
    "- Blood Donor (0)\n",
    "- No Blood Donor (1)\n",
    "\n",
    "Nesta etapa tamb√©m √© realizada a indexa√ß√£o das posi√ß√µes referentes as amostras dos casos suspeitos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0 -1 -1 -1 -1 -1 -1 -1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1]\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "suspect_index=[]\n",
    "for i in range(0,len(y)):\n",
    "    if(y[i]==1):\n",
    "        y[i]=-1\n",
    "        suspect_index.append(i)\n",
    "    if(y[i]>=2):\n",
    "        y[i]=1\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divis√£o do dataset entre casos supeitos e casos confi√°veis\n",
    "Com a utiliza√ß√£o do array dos index das amostras suspeitas √© realizada uma c√≥pia dos atributos dessas amostras, as quais s√£o armazenadas em x_suspect. E, de modo subsequente, todas os dados dos casos suspeitos s√£o apagados do dataset x e y. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[533, 534, 535, 536, 537, 538, 539]\n"
     ]
    }
   ],
   "source": [
    "print(suspect_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X para os casos suspeitos:\n",
      " [[ 47.     0.    22.5  124.    79.5   46.7    2.3    6.83   4.3  170.\n",
      "  345.6   58.6 ]\n",
      " [ 48.     0.    24.9  116.9   49.2   24.3    4.9    3.44   5.25  29.\n",
      "   83.    47.8 ]\n",
      " [ 49.     0.    21.6   42.2    9.5   10.6    2.4    3.75   3.01  64.\n",
      "   38.9   44.8 ]\n",
      " [ 55.     0.    47.3  106.   208.8  130.6    0.8   14.8    8.08  76.\n",
      "   71.6   78.3 ]\n",
      " [ 71.     0.    14.9   69.8   19.7   95.2    9.8   13.3    2.61   9.\n",
      "    7.6   47.  ]\n",
      " [ 74.     0.    20.3   84.    22.8   43.     5.7    4.91   3.19  52.\n",
      "  218.3   47.8 ]\n",
      " [ 59.     1.    19.3  208.2  325.3  146.6    6.9    5.33   4.72  32.\n",
      "  295.6   53.1 ]]\n"
     ]
    }
   ],
   "source": [
    "#C√≥pia dos dados x das amostras suspeitas para um novo array \n",
    "x_suspect=[0]*len(suspect_index)\n",
    "for i in range (0, len(suspect_index)):\n",
    "    x_suspect[i]=x[suspect_index[i]] #Salva os valores dos casos suspeitos em um array separado\n",
    "x_suspect=np.array(x_suspect)#Converte a lista para numpy\n",
    "\n",
    "print(\"X para os casos suspeitos:\\n\", x_suspect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y dos doadores e n√£o doadores:\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      "Y para os casos suspeitos:\n",
      " [-1, -1, -1, -1, -1, -1, -1]\n"
     ]
    }
   ],
   "source": [
    "#Retirada dos valores suspeitos do y\n",
    "y = np.delete(y, suspect_index, axis=0)\n",
    "print(\"Y dos doadores e n√£o doadores:\\n\", y)\n",
    "\n",
    "#Anexa√ß√£o do label -1 para os suspeitos\n",
    "y_suspect=[-1]*len(suspect_index)\n",
    "print(\"\\nY para os casos suspeitos:\\n\", y_suspect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 32.    0.   38.5 ... 106.   12.1  69. ]\n",
      " [ 32.    0.   38.5 ...  74.   15.6  76.5]\n",
      " [ 32.    0.   46.9 ...  86.   33.2  79.3]\n",
      " ...\n",
      " [ 64.    1.   29.  ...  66.7  64.2  82. ]\n",
      " [ 46.    1.   33.  ...  52.   50.   71. ]\n",
      " [ 59.    1.   36.  ...  67.   34.   68. ]]\n"
     ]
    }
   ],
   "source": [
    "# exclus√£o dos casos suspetios do dataset confi√°vel\n",
    "x = np.delete(x, suspect_index, axis=0)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividindo a base confi√°vel em amostras de treinamento e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constru√ß√£o da Rede Neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adicionando neur√¥nios e camadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Camada de entrada\n",
    "ann.add(tf.keras.layers.Dense(units=12, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Camada de sa√≠da\n",
    "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinando a Rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6195 - accuracy: 0.7160\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 935us/step - loss: 0.5607 - accuracy: 0.7942\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 750us/step - loss: 0.5105 - accuracy: 0.8395\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 624us/step - loss: 0.4691 - accuracy: 0.8745\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 872us/step - loss: 0.4355 - accuracy: 0.8909\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4060 - accuracy: 0.9033\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3801 - accuracy: 0.9053\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3574 - accuracy: 0.9115\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3380 - accuracy: 0.9177\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 935us/step - loss: 0.3204 - accuracy: 0.9177\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3048 - accuracy: 0.9198\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2912 - accuracy: 0.9198\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 997us/step - loss: 0.2789 - accuracy: 0.9239\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2670 - accuracy: 0.9239\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 935us/step - loss: 0.2564 - accuracy: 0.9280\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 935us/step - loss: 0.2466 - accuracy: 0.9342\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2379 - accuracy: 0.9383\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2299 - accuracy: 0.9403\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 935us/step - loss: 0.2223 - accuracy: 0.9444\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2152 - accuracy: 0.9444\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 685us/step - loss: 0.2085 - accuracy: 0.9465\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 873us/step - loss: 0.2024 - accuracy: 0.9465\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 997us/step - loss: 0.1964 - accuracy: 0.9486\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1910 - accuracy: 0.9486\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 872us/step - loss: 0.1855 - accuracy: 0.9506\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1804 - accuracy: 0.9527\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1755 - accuracy: 0.9527\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 997us/step - loss: 0.1710 - accuracy: 0.9547\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1667 - accuracy: 0.9547\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 997us/step - loss: 0.1625 - accuracy: 0.9547\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1583 - accuracy: 0.9609\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 748us/step - loss: 0.1545 - accuracy: 0.9650\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1508 - accuracy: 0.9650\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1469 - accuracy: 0.9650\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1434 - accuracy: 0.9650\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 997us/step - loss: 0.1403 - accuracy: 0.9671\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 935us/step - loss: 0.1372 - accuracy: 0.9691\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 935us/step - loss: 0.1345 - accuracy: 0.9691\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 810us/step - loss: 0.1317 - accuracy: 0.9691\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 935us/step - loss: 0.1293 - accuracy: 0.9691\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 748us/step - loss: 0.1270 - accuracy: 0.9691\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1247 - accuracy: 0.9691\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1226 - accuracy: 0.9691\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1205 - accuracy: 0.9691\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1185 - accuracy: 0.9691\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 935us/step - loss: 0.1165 - accuracy: 0.9691\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1147 - accuracy: 0.9691\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1128 - accuracy: 0.9691\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 935us/step - loss: 0.1111 - accuracy: 0.9691\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1094 - accuracy: 0.9712\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1079 - accuracy: 0.9712\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1062 - accuracy: 0.9712\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 997us/step - loss: 0.1048 - accuracy: 0.9712\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 748us/step - loss: 0.1034 - accuracy: 0.9712\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1019 - accuracy: 0.9712\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 748us/step - loss: 0.1006 - accuracy: 0.9712\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 873us/step - loss: 0.0993 - accuracy: 0.9712\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 873us/step - loss: 0.0980 - accuracy: 0.9712\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 997us/step - loss: 0.0968 - accuracy: 0.9733\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 873us/step - loss: 0.0958 - accuracy: 0.9733\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 935us/step - loss: 0.0947 - accuracy: 0.9733\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 748us/step - loss: 0.0934 - accuracy: 0.9733\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 935us/step - loss: 0.0925 - accuracy: 0.9733\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 685us/step - loss: 0.0915 - accuracy: 0.9733\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 748us/step - loss: 0.0905 - accuracy: 0.9733\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 686us/step - loss: 0.0895 - accuracy: 0.9753\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 873us/step - loss: 0.0885 - accuracy: 0.9753\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 873us/step - loss: 0.0878 - accuracy: 0.9774\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 686us/step - loss: 0.0869 - accuracy: 0.9774\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0859 - accuracy: 0.9774\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 748us/step - loss: 0.0851 - accuracy: 0.9774\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0843 - accuracy: 0.9774\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 873us/step - loss: 0.0834 - accuracy: 0.9774\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 748us/step - loss: 0.0826 - accuracy: 0.9774\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 997us/step - loss: 0.0817 - accuracy: 0.9774\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 686us/step - loss: 0.0812 - accuracy: 0.9794\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0804 - accuracy: 0.9794\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 748us/step - loss: 0.0795 - accuracy: 0.9794\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 873us/step - loss: 0.0787 - accuracy: 0.9794\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 935us/step - loss: 0.0780 - accuracy: 0.9794\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 935us/step - loss: 0.0773 - accuracy: 0.9794\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 873us/step - loss: 0.0767 - accuracy: 0.9794\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 873us/step - loss: 0.0762 - accuracy: 0.9815\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0754 - accuracy: 0.9815\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 810us/step - loss: 0.0748 - accuracy: 0.9815\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 997us/step - loss: 0.0742 - accuracy: 0.9835\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 748us/step - loss: 0.0734 - accuracy: 0.9835\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 935us/step - loss: 0.0729 - accuracy: 0.9835\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 747us/step - loss: 0.0723 - accuracy: 0.9835\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 935us/step - loss: 0.0718 - accuracy: 0.9835\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 810us/step - loss: 0.0712 - accuracy: 0.9835\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 934us/step - loss: 0.0707 - accuracy: 0.9835\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 810us/step - loss: 0.0700 - accuracy: 0.9835\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 935us/step - loss: 0.0694 - accuracy: 0.9835\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 748us/step - loss: 0.0690 - accuracy: 0.9835\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 872us/step - loss: 0.0686 - accuracy: 0.9835\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 810us/step - loss: 0.0680 - accuracy: 0.9835\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 935us/step - loss: 0.0675 - accuracy: 0.9835\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 873us/step - loss: 0.0670 - accuracy: 0.9835\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 810us/step - loss: 0.0665 - accuracy: 0.9835\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e2c1d001f0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.fit(X_train, y_train, batch_size = 32, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predi√ß√£o dos resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = ann.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[108   1]\n",
      " [  1  12]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9836065573770492"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Matriz de Confus√£o\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
